# -*- coding: utf-8 -*-
"""book.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EP_m9W9yILFvGePpo4V8q7qgEi0t86nO
"""

# ===============================
# Preprocessing Books Dataset (Fixed)
# ===============================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Load dataset
file_path = "/content/Books_Data_Clean.csv"
df = pd.read_csv(file_path)

# 2. Show basic info
print("Shape:", df.shape)
print("\nColumns:", df.columns.tolist())
print("\nMissing Values:\n", df.isnull().sum())

# 3. Handle missing values
df = df.dropna(thresh=len(df.columns) - 2)   # drop rows with too many NaNs
df = df.fillna("Unknown")                    # fill remaining NaNs with "Unknown"

# 4. Remove duplicates
df = df.drop_duplicates()

# 5. Clean text columns (detect automatically)
text_cols = df.select_dtypes(include=['object']).columns
for col in text_cols:
    df[col] = df[col].astype(str).str.strip().str.lower()

# 6. Handle numeric columns
num_cols = df.select_dtypes(include=['int64','float64']).columns
for col in num_cols:
    # replace negatives with NaN (if any)
    df[col] = df[col].apply(lambda x: np.nan if isinstance(x,(int,float)) and x < 0 else x)
    # fill NaN with median
    df[col] = df[col].fillna(df[col].median())

# 7. Encode categorical features (optional, for ML)
df_encoded = pd.get_dummies(df, drop_first=True)

# 8. Save processed dataset
df.to_csv("/content/Books_Data_Preprocessed.csv", index=False)
print("\nâœ… Preprocessed dataset saved as Books_Data_Preprocessed.csv")

# 9. Quick visualization of missing values
plt.figure(figsize=(8,5))
sns.heatmap(df.isnull(), cbar=False, cmap="viridis")
plt.title("Missing Values Heatmap")
plt.show()